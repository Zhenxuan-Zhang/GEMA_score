{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a988df84-6b9d-41a1-bf10-ba33b20e45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Dify API configuration\n",
    "# DIFY_API_KEY = 'app-EVddrjtP93NAHDGvsTuO7uwW'\n",
    "# DIFY_API_URL = 'https://lyson-dify.zeabur.app/v1'\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Dify API configuration\n",
    "DIFY_API_KEY = 'app-7pO61PZG6wDvrYmEZ5ciRWAu'\n",
    "DIFY_API_URL = 'https://api.dify.ai/v1'\n",
    "\n",
    "def analyze_medical_reports(ground_truth_report, candidate_report):\n",
    "    \"\"\"\n",
    "    This function demonstrates how to submit two text inputs (GroundTruth and Candidate)\n",
    "    to Dify and retrieve the results returned by the multi-agent model.\n",
    "    \"\"\"\n",
    "    # 1) Construct request headers\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {DIFY_API_KEY}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    # 2) Construct request body (chat_data) â€” Modify this according to your multi-agent application configuration\n",
    "    chat_data = {\n",
    "        # The \"inputs\" section can contain multiple key-value pairs corresponding to input nodes in the Dify backend\n",
    "        'inputs': {\n",
    "            'GroundTruth_medical_report': ground_truth_report,\n",
    "            'Candidate_medical_report': candidate_report\n",
    "        },\n",
    "        'query': 'Evaluate these medical reports.',  # You can customize this query or prompt\n",
    "        'user': 'user-123',  # Identifies the user\n",
    "        'response_mode': 'blocking'  # Forces the API to wait for a complete response before returning\n",
    "    }\n",
    "\n",
    "    # 3) Send a request to the /chat-messages endpoint (or the corresponding API path in your Dify backend)\n",
    "    chat_response = requests.post(\n",
    "        f'{DIFY_API_URL}/chat-messages',\n",
    "        headers=headers,\n",
    "        json=chat_data\n",
    "    )\n",
    "\n",
    "    # 4) Return the result\n",
    "    if chat_response.status_code == 200:\n",
    "        response_data = chat_response.json()\n",
    "        # Assuming the returned JSON contains an 'answer' field or other response fields\n",
    "        return response_data.get('answer', 'No answer found.')\n",
    "    else:\n",
    "        # Print error message if the request fails\n",
    "        print(\"Request failed:\", chat_response.status_code, chat_response.text)\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example call\n",
    "    ground_truth = \"the heart is normal in size . the mediastinum is unremarkable . the lungs are clear . there is no pleural line is no pneumothorax or costophrenic xxxx are seen .\"\n",
    "    candidate = \"artifact in the region of the central upper abdomen . no focal areas of consolidation . no pleural effusions . no evidence of pneumothorax . heart size within normal limits . osseous structures intact .\"\n",
    "\n",
    "    result = analyze_medical_reports(ground_truth, candidate)\n",
    "    print(\"Multi-Agent Result:\\n\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
